{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30587,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# N-Steps Lookahead Agent Implemented With Numpy, Alpha/Beta Pruning, and Optimizations","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# imports\nimport numpy as np # importing numpy\nfrom kaggle_environments import make, evaluate # importing game environment\nimport inspect # submission file","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-07T20:36:51.117817Z","iopub.execute_input":"2023-12-07T20:36:51.118292Z","iopub.status.idle":"2023-12-07T20:36:51.124953Z","shell.execute_reply.started":"2023-12-07T20:36:51.118258Z","shell.execute_reply":"2023-12-07T20:36:51.123312Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def my_agent(obs, config) -> int:\n    import numpy as np # just in case\n    \n    # utilites and helpers\n    \n    def drop_piece(board: np.ndarray, column: int, mark: int) -> np.ndarray:\n        if board[0,column] != 0: #is_illegal_action = board[0, column]...\n            raise ValueError(\"Illegal Action!\")\n        next_board = board.copy()\n        row = np.max(np.where(board[:, column] == 0))#[0][-1]\n        next_board[row, column] = mark\n        return next_board\n    \n    def count_marks(board: np.ndarray, num_marks: int, mark: int, win_cond: int = 4) -> int:\n        #function to check marks and empty positions\n        count = 0\n        mark_check = lambda window: np.sum(window == mark) == num_marks\n        space_check = lambda window: np.sum(window == 0) == win_cond - num_marks\n\n        # row and column check\n        for direction in [board, board.T]:\n            for i in range(direction.shape[0] - win_cond + 1):\n                for j in range(direction.shape[1] - win_cond + 1):\n                    window = direction[i:i+win_cond, j:j+win_cond]\n                    count += mark_check(window) and space_check(window)\n                    \n        # diagonal check\n        for i in range(board.shape[0] - win_cond + 1):\n            for j in range(board.shape[1] - win_cond + 1):\n                window = board[i:i+win_cond, j:j+win_cond]\n                ascending_diag = window.diagonal()\n                descending_diag = np.fliplr(window).diagonal()\n                count += (mark_check(ascending_diag) and space_check(ascending_diag)) or \\\n                         (mark_check(descending_diag) and space_check(descending_diag))\n        return count\n    \n    # function to check for 4 marks in a row. If found returns True\n    def is_winner(board: np.ndarray, mark: int, win_cond: int = 4) -> bool:\n        target = np.array([mark] * win_cond) # winning combo\n        \n        # row check\n        for i in range(board.shape[1] - win_cond + 1):\n            found = np.any(np.all(target == board[:, i:i+win_cond], axis = 1))\n            if found:\n                return True\n        # column check\n        for j in range(board.shape[0] - win_cond + 1):\n            found = np.any(np.all(target == board[j:j+win_cond, :].T, axis = 1))\n            if found:\n                return True\n        for i in range(board.shape[0] - win_cond + 1):\n            for j in range(board.shape[1] - win_cond + 1):\n                ascending_diag = board[i:i+win_cond, j:j+win_cond].diagonal()\n                descending_diag = np.fliplr(board[i:i+win_cond, j:j+win_cond]).diagonal()\n                if np.all(ascending_diag == target) or np.all(descending_diag == target):\n                    return True\n        return False # returns false if no rows of 4 are found\n    \n    #definition to determine if game is over\n    def game_finished(board: np.ndarray, win_cond: int = 4) -> bool:\n        return (board == 0).sum() == 0 or \\\n            is_winner(board, 1, win_cond) or \\\n            is_winner(board, 2, win_cond)\n    \n    # scores the detected patterns on the board\n    def score_board(board: np.array) -> float:\n        \n        pattern_scores = {\n            4: 1e10, # 4 of your marks in a line\n            3: 1e5, # 3 of your marks in a line\n            2: 1e2,# 2 of your marks in a line\n            -2: -1, # 2 of opponents marks in a line\n            -3: 1e6,# 3 of opponents marks in a line\n            -4: 1e8 # 4 of opponents marks in a line\n        }\n        \n        weighted_score = 0\n        for pattern, pattern_score in pattern_scores.items():\n            mark = 1 if pattern > 0 else - 1\n            counts = count_marks(board, abs(pattern), mark)\n            weighted_score += counts * pattern_score\n        return weighted_score\n    \n    # function used to determine if the opponent is about to win\n    def is_critical(board: np.ndarray, mark: int, win_cond: int = 4) -> bool:\n        for c in range(board.shape[1]):\n            for r in range(board.shape[0] - 1, -1, -1):  # Starting from bottom row\n\n                # horizontal win check\n                if c + win_cond <= board.shape[1]:\n                    window = board[r, c:c+win_cond]\n                    if (window == mark).sum() == win_cond - 1 and (window == 0).sum() == 1:\n                        if r == board.shape[0] - 1 or board[r+1, c + np.where(window == 0)[0][0]] != 0:\n                            return True\n\n                # vertical win check\n                if r >= win_cond - 1:\n                    window = board[r - win_cond + 1: r + 1, c]\n                    if (window == mark).sum() == win_cond - 1 and (window == 0).sum() == 1:\n                        return True\n\n                # diagonal win check (down-right)\n                if r + win_cond <= board.shape[0] and c + win_cond <= board.shape[1]:\n                    window = board[range(r, r + win_cond), range(c, c + win_cond)]\n                    if (window == mark).sum() == win_cond - 1 and (window == 0).sum() == 1:\n                        empty_index = np.where(window == 0)[0][0]\n                        if r + empty_index == board.shape[0] - 1 or board[r + empty_index + 1, c + empty_index] != 0:\n                            return True\n\n                # diagonal win check (up-right)\n                if r - win_cond + 1 >= 0 and c + win_cond <= board.shape[1]:\n                    window = board[range(r, r - win_cond, -1), range(c, c + win_cond)]\n                    if (window == mark).sum() == win_cond - 1 and (window == 0).sum() == 1:\n                        empty_index = np.where(window == 0)[0][0]\n                        if r - empty_index == 0 or board[r - empty_index - 1, c + empty_index] != 0:\n                            return True\n\n        return False\n\n\n    #implementation of minmax search with alpha beta pruning\n    def minmax_search(board: np.ndarray, depth: int, alpha: float, beta: float, is_maxing: bool) -> float:\n        if depth == 0 or game_finished(board):\n            return score_board(board)\n        #print(is_critical(board, -1))\n        if is_critical(board, -1): return -np.Inf #if opponent is about to win reutn -inf\n        legal_actions = np.where(board[0] == 0)[0]\n        if is_maxing:\n            value = - np.Inf\n            for action in legal_actions:\n                child_board = drop_piece(board, action, 1)\n                value = max(value, minmax_search(child_board, depth-1, alpha, beta, False))\n                alpha = max(alpha, value)\n                if alpha >= beta: break # beta cut-off\n            return value\n        else :\n            value = np.Inf\n            for action in legal_actions:\n                child_board = drop_piece(board, action, -1) \n                value = min(value, minmax_search(child_board, depth-1, alpha, beta, True))\n                beta = min(beta, value)\n                if beta <= alpha: break #alpha cut-off\n            return value\n        \n    # function to go n steps down game tree, score leaf nodes, then go up tree using minmax search\n    # returns all available scores in current turn.\n    def compute_scores(board: np.ndarray, n: int) -> np.array:\n        scores = np.full(board.shape[1], -np.Inf)\n        legal_actions = np.where(board[0] == 0)[0]\n        for action in legal_actions:\n            next_board = drop_piece(board, action, 1)\n            scores[action] = minmax_search(next_board, n-1, -np.Inf, np.Inf, False)\n        return scores\n    \n    # N-steps lookahead agent \n    try :\n        use_board = np.array(obs.board).reshape(config.rows, config.columns)\n        # board encoding, -1 = opponent mark, 1 = agent mark\n        opponent = 3 - obs.mark\n        use_board[use_board == opponent] = -1\n        use_board[use_board == obs.mark] = 1\n        \n        # agent selecting action\n        depth = 2\n        scores = compute_scores(use_board, depth)\n        legal_actions = np.where(use_board[0] == 0)[0]\n        legal_scores = scores[legal_actions]\n        \n        if np.any(legal_scores > -np.Inf): # choose best legal action that does not lose\n            best_actions = legal_actions[np.where(legal_scores == np.amax(legal_scores))[0]]\n            best_ovr_action = best_actions[np.argmin(abs(best_actions - config.columns//2))]\n        else: # if all legal moves result in a loss, choose random legal move \n             best_ovr_action = np.random.choice(legal_actions)\n        \n        #best_ovr_action = np.random.choice(best_scored_actions)\n        return int(best_ovr_action)\n    \n    # just in case\n    except Exception as e: # exception to prevent the agent from making illegal moves\n        print(e)\n        legal_actions = np.where(use_board[0] == 0)[0]\n        #legal_ovr_action = legal_actions[np.argmin(abs(legal_actions - config.columns//2))]\n        return int(np.random.choice(legal_actions))\n        #return int(legal_ovr_action)\n    ","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-12-07T20:36:51.134147Z","iopub.execute_input":"2023-12-07T20:36:51.134705Z","iopub.status.idle":"2023-12-07T20:36:51.185025Z","shell.execute_reply.started":"2023-12-07T20:36:51.134667Z","shell.execute_reply":"2023-12-07T20:36:51.183307Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# make game environment\n# set debug = True to see errors if agent refuses to run\nenv = make('connectx', debug = True)\n\n# play : agent vs random\nenv.run([my_agent, 'negamax'])\n\n# render game\nenv.render(mode = 'ipython')","metadata":{"execution":{"iopub.status.busy":"2023-12-07T20:36:51.187302Z","iopub.execute_input":"2023-12-07T20:36:51.187734Z","iopub.status.idle":"2023-12-07T20:36:56.254781Z","shell.execute_reply.started":"2023-12-07T20:36:51.187675Z","shell.execute_reply":"2023-12-07T20:36:56.253435Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# custom function used to calculate win percentage of model \n# and to determine invalid moves.\ndef get_win_percentages(agent1, agent2, n_rounds=100):\n    config = {'rows': 6, 'columns': 7, 'inarow': 4}\n    # agent 1 goes first (roughly) half the time          \n    outcomes = evaluate(\"connectx\", [agent1, agent2], config, [], n_rounds//2)\n    # agent 2 goes first (roughly) half the time      \n    outcomes += [[b,a] for [a,b] in evaluate(\"connectx\", [agent2, agent1], config, [], n_rounds-n_rounds//2)]\n    print(\"Agent 1 Win Percentage:\", np.round(outcomes.count([1,-1])/len(outcomes), 2))\n    print(\"Agent 2 Win Percentage:\", np.round(outcomes.count([-1,1])/len(outcomes), 2))\n    print()\n    print(\"Number of Invalid Plays by Agent 1:\", outcomes.count([None, 0]))\n    print(\"Number of Invalid Plays by Agent 2:\", outcomes.count([0, None]))","metadata":{"execution":{"iopub.status.busy":"2023-12-07T20:36:56.256277Z","iopub.execute_input":"2023-12-07T20:36:56.256881Z","iopub.status.idle":"2023-12-07T20:36:56.268113Z","shell.execute_reply.started":"2023-12-07T20:36:56.256811Z","shell.execute_reply":"2023-12-07T20:36:56.266610Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"get_win_percentages(my_agent, 'negamax', n_rounds = 25)","metadata":{"execution":{"iopub.status.busy":"2023-12-07T20:36:56.270035Z","iopub.execute_input":"2023-12-07T20:36:56.270457Z","iopub.status.idle":"2023-12-07T20:38:41.910912Z","shell.execute_reply.started":"2023-12-07T20:36:56.270423Z","shell.execute_reply":"2023-12-07T20:38:41.909256Z"},"trusted":true},"outputs":[],"execution_count":null}]}